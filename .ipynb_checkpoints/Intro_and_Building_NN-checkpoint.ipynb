{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cb94c224"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1252a2f7",
    "outputId": "58324b72-24a1-4ab4-a7d6-e4f1eaad378a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.,  3.])\n",
      "Wall time: 53.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = torch.Tensor([5,3]) #a tensor is a multidimensional array\n",
    "y = torch.Tensor([2,1])\n",
    "print(x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7fc8149d",
    "outputId": "45083ab8-f88d-48aa-aaa4-2cd134a796c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros([2,5])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d356670d",
    "outputId": "6497733c-105d-4e21-d6f9-ddb36fba219e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e3891991",
    "outputId": "aac2e011-06bc-40fc-ce11-9391a9146b1d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2658, 0.9630, 0.2523, 0.2924, 0.5127],\n",
       "        [0.4900, 0.7715, 0.3365, 0.0636, 0.6509]])"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand([2,5]) #an array of random values btw 0 and 1 with 2 rows 5 cols\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "14d6ad39",
    "outputId": "4d5234a6-cd31-41af-8bb0-5680e3faaee5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2658, 0.9630, 0.2523, 0.2924, 0.5127, 0.4900, 0.7715, 0.3365, 0.0636,\n",
       "         0.6509]])"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.view([1,10]) #this reshapes the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b05016b5"
   },
   "outputs": [],
   "source": [
    "y = y.view([1,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7b97e111",
    "outputId": "c366b745-f933-427c-8dc0-21d05bbcc0ec",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2658, 0.9630, 0.2523, 0.2924, 0.5127, 0.4900, 0.7715, 0.3365, 0.0636,\n",
       "         0.6509]])"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0d3f1af3"
   },
   "outputs": [],
   "source": [
    "train = datasets.MNIST('',train=True,download=True,\n",
    "                      transform = transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test = datasets.MNIST('',train=False,download=True,\n",
    "                      transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "22b10d65"
   },
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size = 10, shuffle = True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size = 10, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "72f86db0",
    "outputId": "28e82005-f443-4f0a-8366-e0adabb5bcfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([5, 4, 1, 5, 5, 1, 1, 1, 8, 9])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88cd15f5",
    "outputId": "24fa6a3b-6d14-465e-9e36-60505264212f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n"
     ]
    }
   ],
   "source": [
    "x,y = data[0][0], data[1][0]#x is the input data (the thing we want to predict) y is the label, the classification.\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ecfae128",
    "outputId": "be00bdaa-4813-4a58-d0ba-586d801f5d4d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x.view([28,28]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b691b793",
    "outputId": "fea7194b-6045-454d-ff60-9082f84828ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949} 60000\n",
      "Wall time: 4.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total = 0\n",
    "counter_dict = {x:0 for x in range(10)}\n",
    "\n",
    "for data in trainset:\n",
    "    xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] +=1\n",
    "        total+=1\n",
    "        \n",
    "print(counter_dict,total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "46d43c59",
    "outputId": "0a2b8f37-0a6f-4d80-a67e-5c5c32f03ccc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 9.871666666666666\n",
      "1: 11.236666666666666\n",
      "2: 9.93\n",
      "3: 10.218333333333334\n",
      "4: 9.736666666666666\n",
      "5: 9.035\n",
      "6: 9.863333333333333\n",
      "7: 10.441666666666666\n",
      "8: 9.751666666666667\n",
      "9: 9.915000000000001\n"
     ]
    }
   ],
   "source": [
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i]/total*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d41e19b8",
    "outputId": "d76c8696-de97-4ff6-ff9a-d4833730f63a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__() #super() ensures that the init fn in parent class is run\n",
    "        self.fc1 = nn.Linear(28*28,64) #fc1 is first connection 1. 28*28 is the flattened image size. Linear because linear nn\n",
    "        self.fc2 = nn.Linear(64,64) #input of fc2 is output of fc1, i.e. 64\n",
    "        self.fc3 = nn.Linear(64,64)\n",
    "        self.fc4 = nn.Linear(64,10) #output 10 because we have 10 classes in our dict\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x)) #relu is the rectified linear. it is an activation function that ensures the neuron is 'firing'\n",
    "        x = F.relu(self.fc2(x))      \n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return F.log_softmax(x,dim=1) #dim 1 means we are distributing across the output layer tensors\n",
    "        \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "67289a62"
   },
   "outputs": [],
   "source": [
    "X = torch.rand(28,28)\n",
    "X = X.view(-1,28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e949304a",
    "outputId": "6c06e98b-fb7d-4011-e78e-8e0dbedaa110"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3481, -2.3249, -2.2461, -2.2606, -2.2303, -2.4164, -2.2056, -2.2672,\n",
       "         -2.4077, -2.3434]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = net(X)\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Intro and Building NN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
