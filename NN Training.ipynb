{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST('',train=True,download=True, transform = transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test = datasets.MNIST('',train=False,download=True, transform = transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "trainset = torch.utils.data.DataLoader(train,batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test,batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__() #super() ensures that the init fn in parent class is run\n",
    "        self.fc1 = nn.Linear(28*28,64) #fc1 is first connection 1. 28*28 is the flattened image size. Linear because linear nn\n",
    "        self.fc2 = nn.Linear(64,64) #input of fc2 is output of fc1, i.e. 64\n",
    "        self.fc3 = nn.Linear(64,64)\n",
    "        self.fc4 = nn.Linear(64,10) #output 10 because we have 10 classes in our dict\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x)) #relu is the rectified linear. it is an activation function that ensures the neuron is 'firing'\n",
    "        x = F.relu(self.fc2(x))      \n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return F.log_softmax(x,dim=1) #dim 1 means we are distributing across the output layer tensors\n",
    "        \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data used from Pytorch is a nice fancy object that is making our life easy, We just need to iterate over it. Next, we want to calculate loss and specify our optimiser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(),lr=0.001) #lr is the learning rate. Keep it small so the optimizer doesnt bounce around"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One_hot array\n",
    "\n",
    "A one_hot array is an array where only one element is 1 and the rest are 0. The index that is hot is the classification e.g.  \n",
    "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0,] would be 3.\n",
    "\n",
    "### Loss functions\n",
    "\n",
    "Loss functions are a measurement of how far the nn is from the targeted output. A popular one is Mean Squared Error (MSE) but we're trying to use scalar-valued classes.\n",
    "\n",
    "For one_hot, use MSE.\n",
    "For scalar classifications like 0,1,2,3,...,9 use cross entropy.\n",
    "\n",
    "### Optimizer\n",
    "\n",
    "It is the thing that adjusts the model's adjustable parameters like WEIGHTS, slowly over time to fit data. Adam: __ADA__ptive __M__omentum and it is the standard go-to optimizer. Rectified adam is anothe popular one but it is not available in Pytorch yet. Each pass on the entire dataset is called an **EPOCH**. In general there are 3 to 10 EPOCHS. \n",
    "\n",
    "Too few epochs -> model won't learn everything.\n",
    "\n",
    "Too many epochs -> overfitting occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0295, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0686, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3): #3 full passes over the data\n",
    "    for data in trainset: #'data' is a batch of data\n",
    "        X,y = data #X is a batch of features, y is the batch of targets.\n",
    "        net.zero_grad() #sets gradients to 0 before loss calc. You will do this likely every step.\n",
    "        output = net(X.view(-1,784)) #pass in teh reshaped batch (recall they are 28x28 atm)\n",
    "        loss = F.nll_loss(output,y) #calc and grab the loss value\n",
    "        loss.backward() #apple this loss backwards thru the network parameters\n",
    "        optimizer.step() #attempt to optimise weights to account for loss/gradients\n",
    "    print(loss) #Print loss. hope it declines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to do **net.zero_grad()** for every step otherwise the gradients will add up for each pass.\n",
    "\n",
    "### So for each epoch and each batch in our datasets what happens?  \n",
    "1. Grab the features (X) and the labels (y) from the current batch  \n",
    "2. Zero the gradients (net.zero_grad())  \n",
    "3. Pass the data through the network  \n",
    "4. Calculate the loss  \n",
    "5. Adjust weights in the network with hopes of decereasing loss\n",
    "\n",
    "As we iterate, we get loss, which is an important metric but we care about accuracy. So how did we do? Iterate over the test set and measure for correctness by comparing output to target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.966\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1,784))\n",
    "        #print output\n",
    "        for idx, i in enumerate(output):\n",
    "            #print(torch.argmax(i), y[idx])\n",
    "            if torch.argmax(i)==y[idx]:\n",
    "                correct+=1\n",
    "            total +=1\n",
    "            \n",
    "print('Accuracy:',round(correct/total,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAANJ0lEQVR4nO3df6zV9X3H8dcLBBSUFYowgmT1B3aaLVJyg9vsFhamsyQrmLWm/LGwxYlLamKTbqtzSzTZlphl1jTd1gwHK24trUlrYIndZLfNXLPKvBqqULoqDi1yBzpiRe34+d4f98t2wXu+53K+3+/5Hng/H8nNOef7/p7zeefA636/93zOOR9HhABc+Ka03QCA/iDsQBKEHUiCsANJEHYgiYv6Odh0z4iLNaufQwKp/I/e0bE46olqlcJu+1ZJn5M0VdLfRMSDZftfrFm60SurDAmgxI4Y7ljr+TTe9lRJfynpI5Kul7TW9vW9Ph6AZlX5m325pJci4uWIOCbpK5JW19MWgLpVCfsiST8cd3t/se0MttfbHrE9clxHKwwHoIoqYZ/oRYD3vPc2IjZExFBEDE3TjArDAaiiStj3S1o87vYVkg5UawdAU6qE/RlJS2xfaXu6pE9I2lZPWwDq1vPUW0ScsH23pH/S2NTbpojYXVtnAGpVaZ49Ip6Q9ERNvQBoEG+XBZIg7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRRaclm2/skHZF0UtKJiBiqoykA9asU9sIvR8QbNTwOgAZxGg8kUTXsIelJ28/aXj/RDrbX2x6xPXJcRysOB6BXVU/jb4qIA7bnS9pu+/sR8dT4HSJig6QNkjTbc6PieAB6VOnIHhEHistDkh6XtLyOpgDUr+ew255l+7LT1yXdImlXXY0BqFeV0/gFkh63ffpxvhwR/1hLV+ibqR+8prT+gzvnldZPXX6stP7yzZvOuafT9h5/u7S+/rfuKa1f9M1nex77QtRz2CPiZUk31NgLgAYx9QYkQdiBJAg7kARhB5Ig7EASjujfm9pme27c6JV9G69OJ1cs61ib/t3/LL3vK79zXWn9+GXV/g3+5GNf7li7+ZLR0vtOGZs67Wimp/fUUz985+jU0vqfXrW0P40MkB0xrLfi8IT/qBzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJOr5wMoU/2Li5Y23JtB+V3nfB1CdL61Ma/Z07o8HHbtf9e1eX1qfrlT51cn7gyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTDPPkkPvfqrHWtbr/2HPnbSX6u+v6a0fvjdS0rrTy/bUmM3Zzr0zUWl9SuYZz8DR3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJ59sm67Z2OpTVzf730rt/7zOWl9YtHp5XWr3r0QGm9SRf916HS+txl15Y/wFdrbAaVdD2y295k+5DtXeO2zbW93faLxeWcZtsEUNVkTuO/KOnWs7bdK2k4IpZIGi5uAxhgXcMeEU9JOnzW5tWSTn9P02ZJa+ptC0Dden2BbkFEjEpScTm/046219sesT1yXEd7HA5AVY2/Gh8RGyJiKCKGpl3AX34IDLpew37Q9kJJKi7LX7IF0Lpew75N0rri+jpJW+tpB0BTus6z294iaYWkebb3S7pf0oOSHrN9h6RXJX28ySYHwck3S74bvqwm6dq79lUa+0Slezfr9WUz224Bk9Q17BGxtkNpZc29AGgQb5cFkiDsQBKEHUiCsANJEHYgCT7iikrm/NprjT32wZM/Lq2/b++pxsa+EHFkB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkmGdHqfiFG0rrf33tX3V5hIt7HnvXsfeX1i997OmeHzsjjuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATz7Cj1yj1RWr/yot7n0bv5+0M/32WPNxsb+0LEkR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCePbmpC+aX1j+65IXGxn6jy/fC7/38T5fWZ4vPs5+Lrkd225tsH7K9a9y2B2y/Zntn8bOq2TYBVDWZ0/gvSrp1gu0PR8TS4ueJetsCULeuYY+IpyQd7kMvABpU5QW6u20/X5zmz+m0k+31tkdsjxzX0QrDAaii17B/QdLVkpZKGpX0UKcdI2JDRAxFxNA0zehxOABV9RT2iDgYEScj4pSkRyQtr7ctAHXrKey2F467eZukXZ32BTAYus6z294iaYWkebb3S7pf0grbSyWFpH2S7mquRTRp9GPXlNa3LvhGY2P/4ld/r7R+9ZbvNDZ2Rl3DHhFrJ9i8sYFeADSIt8sCSRB2IAnCDiRB2IEkCDuQBB9xvcBNnVe+7PEtv/1vjY5f9jHWy58r/5pq1IsjO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwTz7BW709g+W1rfO/3ylx+/2ddArH/n9jrXFW5qd48eZOLIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBLMs18Aps7puPqWPnrXvzQ69sY3h0rri/+YufRBwZEdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Jgnv0CMLr2uo61P5r3z33sBIOs65Hd9mLb37K9x/Zu2/cU2+fa3m77xeKy8zs7ALRuMqfxJyR9OiKuk/Rzkj5p+3pJ90oajoglkoaL2wAGVNewR8RoRDxXXD8iaY+kRZJWS9pc7LZZ0pqGegRQg3N6gc72ByR9SNIOSQsiYlQa+4UgaX6H+6y3PWJ75LiOVmwXQK8mHXbbl0r6mqRPRcRbk71fRGyIiKGIGJqmGb30CKAGkwq77WkaC/qXIuLrxeaDthcW9YWSDjXTIoA6dJ16s21JGyXtiYjPjittk7RO0oPF5dZGOkRXt9zZ3sdI/3Z4RWn9Gj3dn0bQ1WTm2W+S9BuSXrC9s9h2n8ZC/pjtOyS9KunjjXQIoBZdwx4R35bkDuWV9bYDoCm8XRZIgrADSRB2IAnCDiRB2IEk+IjreWDKzJml9ZlT3mxs7HfjWGl9/r83NjRqxpEdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Jgnv088N+331Bav2/eXzQ29u++9iul9dlb+Lz6+YIjO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwTw7Su1++GdL65fxvfDnDY7sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5DEZNZnXyzpUUk/KemUpA0R8TnbD0i6U9Lrxa73RcQTTTWa2dxdR0rrwz/u/L3yKy95t/S+296ZU1r/iT0/Kq2fKq1ikEzmTTUnJH06Ip6zfZmkZ21vL2oPR8SfN9cegLpMZn32UUmjxfUjtvdIWtR0YwDqdU5/s9v+gKQPSdpRbLrb9vO2N9me8HzQ9nrbI7ZHjutotW4B9GzSYbd9qaSvSfpURLwl6QuSrpa0VGNH/ocmul9EbIiIoYgYmqYZ1TsG0JNJhd32NI0F/UsR8XVJioiDEXEyIk5JekTS8ubaBFBV17DbtqSNkvZExGfHbV84brfbJO2qvz0AdXFElO9gf1jSv0p6Qf8/03KfpLUaO4UPSfsk3VW8mNfRbM+NG72yWscAOtoRw3orDnui2mRejf+2pInuzJw6cB7hHXRAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkun6evdbB7NclvTJu0zxJb/StgXMzqL0Nal8SvfWqzt5+KiIun6jQ17C/Z3B7JCKGWmugxKD2Nqh9SfTWq371xmk8kARhB5JoO+wbWh6/zKD2Nqh9SfTWq7701urf7AD6p+0jO4A+IexAEq2E3fattv/D9ku2722jh05s77P9gu2dtkda7mWT7UO2d43bNtf2dtsvFpflay73t7cHbL9WPHc7ba9qqbfFtr9le4/t3bbvKba3+tyV9NWX563vf7PbnirpB5JulrRf0jOS1kbE9/raSAe290kaiojW34Bh+5ckvS3p0Yj4mWLbn0k6HBEPFr8o50TEZwaktwckvd32Mt7FakULxy8zLmmNpN9Ui89dSV+3qw/PWxtH9uWSXoqIlyPimKSvSFrdQh8DLyKeknT4rM2rJW0urm/W2H+WvuvQ20CIiNGIeK64fkTS6WXGW33uSvrqizbCvkjSD8fd3q/BWu89JD1p+1nb69tuZgILTi+zVVzOb7mfs3VdxrufzlpmfGCeu16WP6+qjbBPtJTUIM3/3RQRyyR9RNIni9NVTM6klvHulwmWGR8IvS5/XlUbYd8vafG421dIOtBCHxOKiAPF5SFJj2vwlqI+eHoF3eLyUMv9/J9BWsZ7omXGNQDPXZvLn7cR9mckLbF9pe3pkj4haVsLfbyH7VnFCyeyPUvSLRq8pai3SVpXXF8naWuLvZxhUJbx7rTMuFp+7lpf/jwi+v4jaZXGXpHfK+kP2+ihQ19XSfpu8bO77d4kbdHYad1xjZ0R3SHp/ZKGJb1YXM4doN7+TmNLez+vsWAtbKm3D2vsT8PnJe0sfla1/dyV9NWX5423ywJJ8A46IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUjifwEStuL177ypywAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X[0].view(28,28))\n",
    "plt.show()\n",
    "\n",
    "print(torch.argmax(net(X[0].view(-1,784))[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What `print(torch.argmax(net(X[0].view(-1,784))[0]))` is doing:  \n",
    "\n",
    "1. Takes in the featureset X[0]\n",
    "2. Reshape it as a 1x784 tensor for the network.\n",
    "3. Gets the output (list of network predictions) after passing through the network. This is due to the \\__init\\__ function.\n",
    "4. The first prediction is the 0th element in the output.\n",
    "5. The prediction is the largest value in this tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
