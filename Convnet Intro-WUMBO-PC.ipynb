{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN vs FC Layers\n",
    "\n",
    "We pass this image in the actual form so we don't need to 'flatten' the image like with fully connected layers. It also can accept 2d and 3d inputs. Hence if we wanted to, we can input 3D printed models. The most typical is a 2D array.\n",
    "\n",
    "The goal of a convolution is to locate the features of an image. The window of a convolution is called a **kernel**. After convoluting, the computer gets back numbers which are identified as features. The computer then does this thing called 'pooling' which is the same thing as a kernel. Of this pool, it finds the max value. \n",
    "\n",
    "**Conv + Pool = HL**  \n",
    "\n",
    "The main concept is that it reduced the image to 'building blocks' and finds features according to those building blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-contrib-python\n",
      "  Using cached opencv_contrib_python-4.5.1.48-cp38-cp38-win_amd64.whl (41.2 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\syazwan\\anaconda3\\lib\\site-packages (from opencv-contrib-python) (1.19.2)\n",
      "Installing collected packages: opencv-contrib-python\n",
      "Successfully installed opencv-contrib-python-4.5.1.48\n"
     ]
    }
   ],
   "source": [
    "#!pip uninstall opencv-python\n",
    "#!pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 83/12501 [00:00<00:14, 829.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PetImagesPC/Cat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12501/12501 [00:15<00:00, 831.77it/s]\n",
      "  1%|▏         | 159/12501 [00:00<00:16, 763.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PetImagesPC/Dog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12501/12501 [00:15<00:00, 787.63it/s]\n",
      "C:\\Users\\Syazwan\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cats:  12476\n",
      "Dogs:  12470\n"
     ]
    }
   ],
   "source": [
    "REBUILD_DATA = False\n",
    "\n",
    "class DogsVSCats():\n",
    "    IMG_SIZE = 50\n",
    "    CATS = 'PetImagesPC/Cat'\n",
    "    DOGS = 'PetImagesPC/Dog'\n",
    "    TESTING = 'PetImagesPC/Testing'\n",
    "    LABELS = {CATS: 0, DOGS:1}\n",
    "    training_data = []\n",
    "    catcount = 0\n",
    "    dogcount = 0\n",
    "    \n",
    "    def make_training_data(self):\n",
    "        for label in self.LABELS:\n",
    "            print(label)\n",
    "            for f in tqdm(os.listdir(label)): #tqdm gives a progress bar\n",
    "                if 'jpg' in f:\n",
    "                    try:\n",
    "                        #print(label,f,str(e))\n",
    "                        path = os.path.join(label,f)\n",
    "                        img = cv.imread(path,cv.IMREAD_GRAYSCALE)\n",
    "                        img = cv.resize(img, (self.IMG_SIZE,self.IMG_SIZE))\n",
    "                        self.training_data.append([np.array(img),np.eye(2)[self.LABELS[label]]])\n",
    "\n",
    "                        if label == self.CATS:\n",
    "                            self.catcount+=1\n",
    "                        elif label ==self.DOGS:\n",
    "                            self.dogcount +=1\n",
    "\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "                        #print(str(e))\n",
    "                    \n",
    "        np.random.shuffle(self.training_data)\n",
    "        np.save('training_data.npy',self.training_data)\n",
    "        print('Cats: ',self.catcount)\n",
    "        print('Dogs: ',self.dogcount)\n",
    "            \n",
    "if REBUILD_DATA:\n",
    "    dogsvcats = DogsVSCats()\n",
    "    dogsvcats.make_training_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np.eye(2)[self.LABELS[label]]` creates a one_hot array with 2 possible outcomes. By passing the index of the outcome, we can get the corresponding one_hot array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.load('training_data.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24946\n",
      "[array([[216, 200, 148, ...,  79,  83,  82],\n",
      "       [219, 196,  99, ...,  77,  80,  75],\n",
      "       [216, 187,  94, ..., 108, 108,  90],\n",
      "       ...,\n",
      "       [ 45,  51,  44, ..., 112, 154, 177],\n",
      "       [ 44,  54,  50, ..., 155, 142, 102],\n",
      "       [ 45,  54,  54, ..., 157, 191, 149]], dtype=uint8)\n",
      " array([0., 1.])]\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data))\n",
    "print(training_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(training_data[1][0], cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5) #1 is input, 32 is no of features, 5 is kernel size\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5) #1 is input, 32 is no of features, 5 is kernel size\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5) #1 is input, 32 is no of features, 5 is kernel size\n",
    "        \n",
    "        x = torch.randn(50,50).view(-1,1,50,50)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self._to_linear,512)\n",
    "        self.fc2 = nn.Linear(512,2)\n",
    "    \n",
    "    def convs(self,x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),(2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),(2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)),(2,2))\n",
    "        #print(x[0].shape)\n",
    "        \n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1,self._to_linear)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x,dim=1)\n",
    "    \n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(training_data[0][0])\n",
    "x = [i[0] for i in training_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2494\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(),lr = 0.001)\n",
    "loss_function= nn.MSELoss()\n",
    "\n",
    "X = torch.Tensor([i[0] for i in training_data]).view(-1,50,50)\n",
    "X = X/255.0 #normalise the data\n",
    "y = torch.Tensor([i[1] for i in training_data])\n",
    "\n",
    "VAL_PCT = 0.1\n",
    "val_size = int(len(X)*VAL_PCT)\n",
    "print(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22452\n",
      "2494\n",
      "24946\n",
      "torch.Size([22452, 2])\n",
      "torch.Size([22452, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "train_X = X[:-val_size]\n",
    "train_y = y[:-val_size]\n",
    "\n",
    "test_X = X[-val_size:]\n",
    "test_Y = y[-val_size:]\n",
    "\n",
    "print(len(train_X))\n",
    "print(len(test_X))\n",
    "print(len(X))\n",
    "print(train_y.shape)\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:48<00:00,  4.62it/s]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2498, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:48<00:00,  4.60it/s]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2498, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:49<00:00,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2498, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100 #if memory limit hit, lower the batch size.\n",
    "EPOCHS = 3 #epochs is a full run over the data\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i in tqdm(range(0,len(train_X), BATCH_SIZE)): #start from 0, end at len(train_X), step is BATCH_SIZE\n",
    "        #print(i, i+BATCH_SIZE)\n",
    "        batch_X = train_X[i:i+BATCH_SIZE].view(-1,1,50,50)\n",
    "        batch_y = train_y[i:i+BATCH_SIZE]\n",
    "        #print('batch_y shape:',batch_y.shape)\n",
    "        \n",
    "        net.zero_grad()\n",
    "        outputs = net(batch_X) #now we have outputs then we can calculate loss\n",
    "        #print('outputs shape:',outputs.shape)\n",
    "        loss = loss_function(outputs,batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2494/2494 [00:04<00:00, 539.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(test_X))):\n",
    "        real_class = torch.argmax(test_Y[i])\n",
    "        net_out = net(test_X[i].view(-1,1,50,50))[0]\n",
    "        predicted_class = torch.argmax(net_out)\n",
    "        if predicted_class == real_class:\n",
    "            correct+=1\n",
    "        total+=1\n",
    "print('Accuracy:',round(correct/total,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
